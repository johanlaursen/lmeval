#!/bin/bash

#SBATCH --account=researchers
#SBATCH --job-name=lmeval_llama    # Job name
#SBATCH --output=logs/R-%x.%j.out      # Name of output file (%j expands to jobId)
#SBATCH --error=logs/R-%x.%j.err     # Error handling
#SBATCH --nodes=1                # Total number of nodes requested
#SBATCH --cpus-per-task=8        # Schedule 8 cores (includes hyperthreading)
#SBATCH --mem=48G
#SBATCH --constraint="rtx8000|a100_40gb|v100|a30" # Use either a v100 or a100
#SBATCH --gres=gpu:1      #v100:1 or a100_40gb:1 on brown
#SBATCH --time=0-12:00:00          # Run time (hh:mm:ss) 
#SBATCH --partition=red,brown    # Run on either the red or brown queue

#srun hostname

# module load Anaconda3
source activate lmeval # Not working???

nvidia-smi


# time python3 eval_single.py "llamaSpanish256" "/home/data_shares/mapillary/lmeval_models/llamaSpanish256"
# time python3 eval_single.py "llama_train_sft_7b" "/home/data_shares/mapillary/lmeval_models/sft/llama-7B"
time python3 eval_single.py "llama_train_sft_13b" "/home/data_shares/mapillary/lmeval_models/sft/llama-13B"
